{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/borrelli2/DSCI-511/blob/main/module_A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJVsxGx0-KBj"
      },
      "source": [
        "## Module submission header\n",
        "### Submission preparation instructions \n",
        "_Completion of this header is mandatory, subject to a 2-point deduction to the assignment._ Only add plain text in the designated areas, i.e., replacing the relevant 'NA's. You must fill out all group member Names and Drexel email addresses in the below markdown list, under header __Module submission group__. It is required to fill out descriptive notes pertaining to any tutoring support received in the completion of this submission under the __Additional submission comments__ section at the bottom of the header. If no tutoring support was received, leave NA in place. You may as well list other optional comments pertaining to the submission at bottom. _Any distruption of this header's formatting will make your group liable to the 2-point deduction._\n",
        "\n",
        "### Module submission group\n",
        "- Group member 1\n",
        "    - Name: Caitlin Dunne\n",
        "    - Email: cd3348@drexel.edu\n",
        "- Group member 2\n",
        "    - Name: Robert Borrelli\n",
        "    - Email: rmb326@drexel.edu\n",
        "- Group member 3\n",
        "    - Name: Brittany Muncie\n",
        "    - Email: btm68@drexel.edu\n",
        "- Group member 4\n",
        "    - Name: Isabel Traore\n",
        "    - Email: iat28@drexel.edu\n",
        "\n",
        "### Additional submission comments\n",
        "- Tutoring support received: NA\n",
        "- Other (other): NA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "_WXB5vLu-hPT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97d155e3-3e32-41e7-a093-a716a784f4b4"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dydsxk9X-KBl"
      },
      "source": [
        "# Assignment Group 1\n",
        "\n",
        "## Module A _(25 points)_\n",
        "\n",
        "__A1.__ _(3 points)_ In this module, you will be working with the [Seinfeld Chronicles dataset](https://www.kaggle.com/thec03u5/seinfeld-chronicles). Create an account on [Kaggle](https://www.kaggle.com) and download the `scripts.csv` file from the dataset and move it into the `data` directory. Read the `data/scripts.csv` file as a text file line-by-line and examine the list you have loaded the data into. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "FbN7f2rr-KBl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "891cca70-e39b-47c6-d6f4-e18c06b3844e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['', 'Character', 'Dialogue', 'EpisodeNo', 'SEID', 'Season'], ['0', 'JERRY', 'Do you know what this is all about? Do you know, why were here? To be out, this is out...and out is one of the single most enjoyable experiences of life. People...did you ever hear people talking about We should go out? This is what theyre talking about...this whole thing, were all out now, no one is home. Not one person here is home, were all out! There are people tryin to find us, they dont know where we are. (on an imaginary phone) Did you ring?, I cant find him. Where did he go? He didnt tell me where he was going. He must have gone out. You wanna go out you get ready, you pick out the clothes, right? You take the shower, you get all ready, get the cash, get your friends, the car, the spot, the reservation...Then youre standing around, whatta you do? You go We gotta be getting back. Once youre out, you wanna get back! You wanna go to sleep, you wanna get up, you wanna go out again tomorrow, right? Where ever you are in life, its my feeling, youve gotta go.', '1.0', 'S01E01', '1.0'], ['1', 'JERRY', '(pointing at Georges shirt) See, to me, that button is in the worst possible spot. The second button literally makes or breaks the shirt, look at it. Its too high! Its in no-mans-land. You look like you live with your mother.', '1.0', 'S01E01', '1.0'], ['2', 'GEORGE', 'Are you through?', '1.0', 'S01E01', '1.0'], ['3', 'JERRY', 'You do of course try on, when you buy?', '1.0', 'S01E01', '1.0'], ['4', 'GEORGE', 'Yes, it was purple, I liked it, I dont actually recall considering the buttons.', '1.0', 'S01E01', '1.0'], ['5', 'JERRY', 'Oh, you dont recall?', '1.0', 'S01E01', '1.0'], ['6', 'GEORGE', '(on an imaginary microphone) Uh, no, not at this time.', '1.0', 'S01E01', '1.0'], ['7', 'JERRY', 'Well, senator, Id just like to know, what you knew and when you knew it.', '1.0', 'S01E01', '1.0'], ['8', 'CLAIRE', 'Mr. Seinfeld. Mr. Costanza.', '1.0', 'S01E01', '1.0']]\n"
          ]
        }
      ],
      "source": [
        "seinfeld_list_line = []\n",
        "seinfeld_reader = csv.reader(open(\"data/scripts.csv\",\"r\"))\n",
        "for line in seinfeld_reader:\n",
        "  seinfeld_list_line.append(line)\n",
        "\n",
        "print(seinfeld_list_line[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tw6ougPf-KBm"
      },
      "source": [
        "__A2.__ _(2 points)_ Is it possible to work with this data, simply splitting by a delimiter? Explain any complexity in the data's structured format that necessitates an established format-specific file reader. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwT4Crp2-KBm"
      },
      "source": [
        "It is not possible to work with this data, simply splitting by a delimeter. Because this dataset is split by commas, much of the dialog data would be split up due to it containing commas. It is also noteworthy that the dialog sometimes includes actions that the actor must perform when speaking the line. These actions are put in paranthesis but still are in the dialog section. The Character and Dialog columns can also be used to show a change in setting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MmrHrBc-KBn"
      },
      "source": [
        "__A3.__ _(5 points)_ Use the `csv` module to read the contents of the `data/scripts.csv` file into a list. Examine this list. How many unique speaking characters are present in the scripts in total? \n",
        "\n",
        "__Important__: please don't get stuck on cleaning text in this module! It's great to take note of issues in data and even address them, but the regular expressions (regex) required to get heavily into that work is ahead in __Chapter 4__ and so not required here. Please just count characters and words as best possible using the topics from Chapters 0&ndash;2 (na√Øvely, even), and utilize the markdown response boxes to discuss what you see as being the challenges in working with these data and what solutions might be."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "sX4H5DI2-KBn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f22f69d8-a869-4a2d-8f32-1f2cd3210a18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amount of Characters: 1640\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "seinfeld_reader = csv.reader(open(\"data/scripts.csv\",\"r\"))\n",
        "seinfeld_list_csv = list(seinfeld_reader)\n",
        "\n",
        "character_list = []\n",
        "\n",
        "for i in seinfeld_list_csv:\n",
        "  if i[1] not in character_list:\n",
        "    character_list.append(i[1])\n",
        "print(\"Amount of Characters: \" + str(len(character_list)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzUT7pCL-KBo"
      },
      "source": [
        "__A4.__ _(2 points)_ Count the dialogue entries for the four major characters, \"JERRY\", \"GEORGE\", \"ELAINE\", and \"KRAMER\", using a dictionary (you are not allowed to use the Counter data structure for any component of this module).  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "BIlNKmtT-KBp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d0e0153-6c81-4095-ab03-138e30ceab59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dialogue Count for each Main Character:\n",
            "{'JERRY': 14786, 'GEORGE': 9708, 'ELAINE': 7983, 'KRAMER': 6664}\n"
          ]
        }
      ],
      "source": [
        "dialogue_counts={\"JERRY\": 0, \"GEORGE\": 0, \"ELAINE\": 0, \"KRAMER\": 0 }\n",
        "\n",
        "for i in seinfeld_list_csv:\n",
        "  if i[1] == \"JERRY\":\n",
        "    dialogue_counts[\"JERRY\"] +=1\n",
        "  elif i[1] == \"GEORGE\":\n",
        "    dialogue_counts[\"GEORGE\"] +=1\n",
        "  elif i[1] == \"ELAINE\":\n",
        "    dialogue_counts[\"ELAINE\"] +=1\n",
        "  elif i[1] == \"KRAMER\":\n",
        "    dialogue_counts[\"KRAMER\"] +=1\n",
        "print(\"Dialogue Count for each Main Character:\")\n",
        "print(dialogue_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1Lj94QC-KBp"
      },
      "source": [
        "__A5.__ _(3 points)_ Count the number of words spoken by each of the main characters using a dictionary. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "2lEN_DWZ-KBp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b33dfab4-6aaa-4a28-85e7-bebad54491f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Count for each Main Character:\n",
            "{'JERRY': 147389, 'GEORGE': 107029, 'ELAINE': 74634, 'KRAMER': 70299}\n"
          ]
        }
      ],
      "source": [
        "word_counts={\"JERRY\": 0, \"GEORGE\": 0, \"ELAINE\": 0, \"KRAMER\": 0 }\n",
        "\n",
        "for i in seinfeld_list_csv:\n",
        "  if i[1] == \"JERRY\":\n",
        "    word_counts[\"JERRY\"] += len(i[2].split())\n",
        "  elif i[1] == \"GEORGE\":\n",
        "    word_counts[\"GEORGE\"] += len(i[2].split())\n",
        "  elif i[1] == \"ELAINE\":\n",
        "    word_counts[\"ELAINE\"] += len(i[2].split())\n",
        "  elif i[1] == \"KRAMER\":\n",
        "    word_counts[\"KRAMER\"] += len(i[2].split())\n",
        "print(\"Word Count for each Main Character:\")\n",
        "print(word_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-dJwYc8-KBp"
      },
      "source": [
        "__A6.__ _(5 points)_ Count how many times each word is spoken by the main characters using a dictionary, then sort these word counts in descending order, i.e. from the most commonly spoken words to least. [__Hint__: You can use either a lambda function or a list comprehension to do this.] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "wJhK_mQ4-KBq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e28bce84-9d9d-4083-a4dc-ca088a541d32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jerry Top 10 Words\n",
            "the       4708\n",
            "I         4665\n",
            "you       3622\n",
            "a         3294\n",
            "to        3059\n",
            "of        1518\n",
            "in        1304\n",
            "and       1282\n",
            "You       1188\n",
            "is        1181\n",
            " \n",
            "George Top 10 Words\n",
            "I         3946\n",
            "the       3136\n",
            "a         2457\n",
            "to        2287\n",
            "you       2269\n",
            "of        1033\n",
            "in         923\n",
            "and        922\n",
            "You        879\n",
            "I'm        823\n",
            " \n",
            "Elaine Top 10 Words\n",
            "I         2604\n",
            "the       1797\n",
            "you       1713\n",
            "a         1557\n",
            "to        1538\n",
            "and        748\n",
            "is         711\n",
            "of         634\n",
            "that       603\n",
            "You        598\n",
            " \n",
            "Kramer Top 10 Words\n",
            "the       2208\n",
            "I         2155\n",
            "a         1560\n",
            "you       1534\n",
            "to        1382\n",
            "and        797\n",
            "of         685\n",
            "in         607\n",
            "I'm        551\n",
            "You        516\n",
            " \n"
          ]
        }
      ],
      "source": [
        "jerry_most_spoken={}\n",
        "george_most_spoken={}\n",
        "elaine_most_spoken={}\n",
        "kramer_most_spoken={}\n",
        "for i in seinfeld_list_csv: \n",
        "  if i[1] == \"JERRY\":    \n",
        "    for word in i[2].split():\n",
        "      if word not in jerry_most_spoken:\n",
        "        jerry_most_spoken[word]=1\n",
        "      else:\n",
        "        jerry_most_spoken[word]+=1\n",
        "  elif i[1] == \"GEORGE\":    \n",
        "    for word in i[2].split():\n",
        "      if word not in george_most_spoken:\n",
        "        george_most_spoken[word]=1\n",
        "      else:\n",
        "        george_most_spoken[word]+=1 \n",
        "  elif i[1] == \"ELAINE\":    \n",
        "    for word in i[2].split():\n",
        "      if word not in elaine_most_spoken:\n",
        "        elaine_most_spoken[word]=1\n",
        "      else:\n",
        "        elaine_most_spoken[word]+=1    \n",
        "  elif i[1] == \"KRAMER\":    \n",
        "    for word in i[2].split():\n",
        "      if word not in kramer_most_spoken:\n",
        "        kramer_most_spoken[word]=1\n",
        "      else:\n",
        "        kramer_most_spoken[word]+=1 \n",
        "     \n",
        "\n",
        "jerry_spoken_sorted = sorted(jerry_most_spoken, reverse = True, key = lambda x: jerry_most_spoken[x])\n",
        "george_spoken_sorted = sorted(george_most_spoken, reverse = True, key = lambda x: george_most_spoken[x])\n",
        "elaine_spoken_sorted = sorted(elaine_most_spoken, reverse = True, key = lambda x: elaine_most_spoken[x])\n",
        "kramer_spoken_sorted = sorted(kramer_most_spoken, reverse = True, key = lambda x: kramer_most_spoken[x])\n",
        "\n",
        "i = 0\n",
        "print(\"Jerry Top 10 Words\")\n",
        "for result in jerry_spoken_sorted:\n",
        "    print('{:<10s}{:>4d}'.format(result, jerry_most_spoken[result]))\n",
        "    i += 1\n",
        "    if i == 10:\n",
        "      print(\" \")\n",
        "      break\n",
        "\n",
        "i = 0\n",
        "print(\"George Top 10 Words\")\n",
        "for result in george_spoken_sorted:\n",
        "    print('{:<10s}{:>4d}'.format(result, george_most_spoken[result]))\n",
        "    i += 1\n",
        "    if i == 10:\n",
        "      print(\" \")\n",
        "      break\n",
        "\n",
        "i = 0\n",
        "print(\"Elaine Top 10 Words\")\n",
        "for result in elaine_spoken_sorted:\n",
        "    print('{:<10s}{:>4d}'.format(result, elaine_most_spoken[result]))\n",
        "    i += 1\n",
        "    if i == 10:\n",
        "      print(\" \")\n",
        "      break      \n",
        "\n",
        "i = 0\n",
        "print(\"Kramer Top 10 Words\")\n",
        "for result in kramer_spoken_sorted:\n",
        "    print('{:<10s}{:>4d}'.format(result, kramer_most_spoken[result]))\n",
        "    i += 1\n",
        "    if i == 10:\n",
        "      print(\" \")\n",
        "      break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6m27Xe5-KBq"
      },
      "source": [
        "__A7.__ _(5 points)_ Load the `data/stop-words.txt` file into a list. Find the 10 most common words for each of the main characters that are not in this list of stop words. Put these most common words in a dictionary data strucutre. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "vIkrAxB3-KBr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "076c8371-c2aa-4d52-ee99-f3694d75f4ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'JERRY': ['I', 'You', \"I'm\", 'What', 'like', 'know', 'get', 'Oh,', 'Well,', 'it.'], 'GEORGE': ['I', 'You', \"I'm\", 'like', 'What', 'know', 'get', \"It's\", 'think', 'got'], 'ELAINE': ['I', 'You', \"I'm\", 'Oh,', 'What', 'know', 'Well,', 'like', 'get', 'got'], 'KRAMER': ['I', \"I'm\", 'You', 'Well,', 'Yeah,', 'Oh,', 'got', 'get', 'know', 'like']}\n"
          ]
        }
      ],
      "source": [
        "stop_words = open(\"data/stop-words.txt\",\"r\")\n",
        "data = stop_words.read()\n",
        "stoplist = data.split(\"\\n\")\n",
        "commonWords = {\n",
        "  \"JERRY\": [],\n",
        "  \"GEORGE\": [],\n",
        "  \"ELAINE\": [],\n",
        "  \"KRAMER\": []\n",
        "}\n",
        "i = 0\n",
        "\n",
        "for word in jerry_spoken_sorted:\n",
        "  if word not in stoplist:\n",
        "    commonWords[\"JERRY\"].append(word)\n",
        "    i += 1\n",
        "    if i == 10:\n",
        "      break    \n",
        "i = 0\n",
        "for word in george_spoken_sorted:\n",
        "  if word not in stoplist:\n",
        "    commonWords[\"GEORGE\"].append(word)\n",
        "    i += 1\n",
        "    if i == 10:\n",
        "      break   \n",
        "i = 0\n",
        "for word in elaine_spoken_sorted:\n",
        "  if word not in stoplist:\n",
        "    commonWords[\"ELAINE\"].append(word)  \n",
        "    i += 1\n",
        "    if i == 10:\n",
        "      break  \n",
        "i = 0 \n",
        "for word in kramer_spoken_sorted:\n",
        "  if word not in stoplist:\n",
        "    commonWords[\"KRAMER\"].append(word)   \n",
        "    i += 1\n",
        "    if i == 10:\n",
        "      break   \n",
        "\n",
        "\n",
        "print(commonWords)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "djouov6hFHHb"
      },
      "execution_count": 53,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "module-A.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}